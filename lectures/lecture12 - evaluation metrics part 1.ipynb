{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudcard\n",
    "- **Is there an ideal k=? Ex. Should we do 4, 5, 10 etc for n_splits**\n",
    "    - There is no clear/magical answer to such questions\n",
    "    - It depends on how much computational power you have, how many unique groups there are in your dataset, etc.\n",
    "- **When we get a new dataset, how can we figure out it is imbalanced data or not?**\n",
    "- **Identifying imbalanced data**\n",
    "    - Follow the EDA-related questions you practiced in PS3 Problem 1a.\n",
    "    - Q3: value_counts() applied to your classification target varible tells you how imbalanced your classification problem is.\n",
    "- **can I use the same dataset for the final project?**\n",
    "    - Same as what? Please be specific.\n",
    "    - You cannot use any of the datasets we cover in class or you work with in the problem sets\n",
    "    - That would be too easy.\n",
    "- **\"Still confused by what \"\"group\"\" does in the GroupShuffleSplit.**\n",
    "    - the variable group describes the group ID of each point in your data\n",
    "- **wondering if there is a threshold, like how many % of class 1 is considered as imbalanced data.**\n",
    "    - same as above, there is no clear/magical answer to such questions\n",
    "    - some people might consider 90-10% ratio imbalanced\n",
    "    - others might consider 99-1% ratio instead\n",
    "    - The closer the fraction of class 1 points is to 0, the more likely the problem is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation metrics in supervised ML, part 1, classification\n",
    "By the end of this lecture, you will be able to\n",
    "- Describe the terms in the confusion matrix\n",
    "- Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)\n",
    "- Choose a metric most appropriate for your problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The supervised ML pipeline\n",
    "\n",
    "**0. Data collection/manipulation**: you might have multiple data sources and/or you might have more data than you need\n",
    "   - you need to be able to read in datasets from various sources (like csv, excel, SQL, parquet, etc)\n",
    "   - you need to be able to filter the columns/rows you need for your ML model\n",
    "   - you need to be able to combine the datasets into one dataframe \n",
    "\n",
    "**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "<span style=\"background-color: #FFFF00\">**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)</span>\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to be transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "<span style=\"background-color: #FFFF00\">**4. Choose an evaluation metric**: depends on the priorities of the stakeholders</span>\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "**6. Tune the hyperparameters of your ML models (aka cross-validation or hyperparameter tuning)**\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "**7. Interpret your model**: black boxes are often not useful\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A word on missing values and preprocessing before we start\n",
    "\n",
    "- missing values in categorical and ordinal features need to be handled during preprocessing\n",
    "- we will cover missing values in continuous features later\n",
    "- DO NOT DROP COLUMNS OR ROWS WITH MISSING VALUES!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical feature: treat missing values as another category\n",
    "\n",
    "- the BEST thing you can do!\n",
    "- already covered in the preprocessing lecture (one hot encoding)\n",
    "- example: missing values in gender\n",
    "    - if survey only has options for male/female, missing values are likely because those people are outside the gender binary\n",
    "    - it is a bad idea to impute (try to guess male or female and thus boxing them into the binary)\n",
    "- example: native country in the adult data\n",
    "    - missing data are represented as ` ?`\n",
    "    - a one-hot encoded feature was assigned to the missing category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values in an ordinal feature\n",
    "\n",
    "- treat missing values as one of the ordinal categories\n",
    "- where does this 'missing' category fits in the ordered list of categories?\n",
    "- usually it's either the first or the last category\n",
    "- if you are uncertain, make an experiment\n",
    "    - pipeline 1: the missing category is the first in the list\n",
    "    - pipeline 2: the missing category is the second in the list\n",
    "    - keep your ML pipeline otherwise unchanged\n",
    "    - check the best validation scores\n",
    "    - If the validation scores of pipeline 1 vs pipeline 2 are significanrtly different, chose whichever pipeline has a better score\n",
    "- Any change in the validation score is attributed to the one change you made\n",
    "- This is the key to scientific experimentation and data-drive decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values in continuous features: more on this later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Back to evaluation metrics!\n",
    "- decide what metric we will use to evaluate the supervised ML model \n",
    "   - this is necessary even before we train the model\n",
    "   - we need to know what single number metric we will use to compare models and to select the best one\n",
    "- sklearn classifiers have two methods to return predictions\n",
    "   - .predict_proba which returns the probability that the point belongs to each class with shape (n_samples, n_classes)\n",
    "   - .predict which returns the predicted class for each point with shape (n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### .predict_proba vs. .predict\n",
    "\n",
    "`y_true = [1 0 1 1 0] # the true labels`\n",
    "\n",
    "`pred_probs = \n",
    "[[0.02796171 0.97203829]\n",
    " [0.89682444 0.10317556]\n",
    " [0.50104129 0.49895871]\n",
    " [0.13713222 0.86286778]\n",
    " [0.95707434 0.04292566]] # predicted probabilities show the model's confidence`\n",
    " \n",
    " `y_pred = [1 0 0 1 0] # predicted class`\n",
    " - pred_probs\n",
    "    - first column is the probability that the point belongs to class 0\n",
    "    - second column is the probability that the point belings to class 1\n",
    "    - the rows sum to 1\n",
    " - y_pred\n",
    "    - 0 if class 0 probability is equal or larger than 50% (or equivalently if class 1 probability is less than 50%)\n",
    "    - 1 if class 0 probability is less than 50% (or equivalently of class 1 probability is equal or larger than 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to transform predicted probabilities to predicted class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 0 1 0 1]\n",
      "[0 1 1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([0,0,1,0,1,1,0,1,0,1]) # the true classification labels of the dataset\n",
    "# pred_probs_class1 is the second column of pred_probs\n",
    "pred_probs_class1 = np.array([0.3, 0.7,  0.55, 0.12, 0.45, 0.89, 0.41, 0.02, 0.29, 0.85])\n",
    "p_crit =  0.5\n",
    "\n",
    "# If predicted probability is < p_crit (by default 0.5), predicted class is 0, otherwise it is 1.\n",
    "y_pred = np.zeros(len(pred_probs_class1),dtype=int)\n",
    "y_pred[pred_probs_class1 < p_crit] = 0\n",
    "y_pred[pred_probs_class1 >= p_crit] = 1\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred) # the predicted classification labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For now, we focus on evaluation metrics applicable to predicted classes!\n",
    "\n",
    "We work with y_true and y_pred arrays.\n",
    "\n",
    "Next, we will work with metrics applicable to pred_probs and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Evaluation metrics in supervised ML, part 1, classification</font>\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- **Describe the terms in the confusion matrix**\n",
    "- <font color='LIGHTGRAY'>Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)</font>\n",
    "- <font color='LIGHTGRAY'>Choose a metric most appropriate for your problem</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The confusion matrix\n",
    "\n",
    "`y_true = [0, 0, 1, 0, 1, 1, 0, 1, 0, 1] # the true classification labels of the dataset`\n",
    "\n",
    "`y_pred = [0, 1, 1, 0, 0, 1, 0, 0, 0, 1] # the predicted classification labels`\n",
    "\n",
    "Let's count how many points we have in four categories:\n",
    "\n",
    "- true label is 0, predicted label is 0 - **True Negatives**\n",
    "- true label is 1, predicted label is 1 - **True Positives**\n",
    "- true label is 0, predicted label is 1 - **False Positive**\n",
    "- true label is 1, predicted label is 0 - **False Negative**\n",
    "\n",
    "Generally, the confusion matrix $C$ is such that $C_{i,j}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Back to our example:\n",
    "\n",
    "`y_true = [0, 0, 1, 0, 1, 1, 0, 1, 0, 1] # the true classification labels of the dataset`\n",
    "\n",
    "`y_pred = [0, 1, 1, 0, 0, 1, 0, 0, 0, 1] # the predicted classification labels`\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0)</td>\n",
    "        <td><b>True Negative (TN): 4</b></td>\n",
    "        <td><b>False Positive (FP): 1</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1)</td>\n",
    "        <td><b>False Negative (FN): 2</b></td>\n",
    "        <td><b>True Positive (TP): 3</b></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [0,0,1,0,1,1,0,1,0,1]\n",
    "y_pred = [0,1,1,0,0,1,0,0,0,1]\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay\n",
    "# check out also https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_true,y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm,display_labels=['class 0', 'class 1'])\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "disp.plot(ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quiz 1\n",
    "\n",
    "Calculate what fraction of the data points are correctly classified in the example below. Visualize the confusion matrix (not part of the quiz)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0,0,2,1,1,0,2,2,2,0,1,1,0,0,0,1])\n",
    "y_pred = np.array([0,1,0,1,0,0,2,2,1,0,1,1,0,0,1,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Evaluation metrics in supervised ML, part 1, classification</font>\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the terms in the confusion matrix</font>\n",
    "- **Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)**\n",
    "- <font color='LIGHTGRAY'>Choose a metric most appropriate for your problem</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metrics derived from $C$\n",
    "$C$ contains $n_{classes}^2$ elements but we need a single number metric to easily compare various models.\n",
    "\n",
    "For two classes:\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0)</td>\n",
    "        <td><b>True Negative (TN)</b></td>\n",
    "        <td><b>False Positive (FP)</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1)</td>\n",
    "        <td><b>False Negative (FN)</b></td>\n",
    "        <td><b>True Positive (TP)</b></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Some single number metrics derived from $C$:\n",
    "- accuracy: fraction of data points correctly classified\n",
    "   - $a = \\sum_i C_{i,i} / \\sum C$ = (TP + TN) / (TP + TN + FP + FN)\n",
    "- recall: what fraction of the condition positive samples are true positives?\n",
    "   - it measures the ability of the classifier to identify all positive samples\n",
    "   - in binary classification: R = TP / (TP + FN)\n",
    "- precision: what fraction of the predicted positive points are true positives?\n",
    "   - it measures the ability of the classifier to not predict a negative sample to be positive\n",
    "   - in binary classification: P = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0)</td>\n",
    "        <td><b>True Negative (TN)</b></td>\n",
    "        <td><b>False Positive (FP)</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1)</td>\n",
    "        <td><b>False Negative (FN)</b></td>\n",
    "        <td><b>True Positive (TP)</b></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "A = (TP + TN) / (TP + TN + FP + FN) \n",
    "\n",
    "R = TP / (TP + FN) = TP / CP\n",
    "\n",
    "P = TP / (TP + FP) = TP / PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The f_beta score\n",
    "Weighted harmonic mean of P and R:\n",
    "### <center> $f_{\\beta} = (1 + \\beta^2) \\frac{P R}{\\beta^2 P + R}$ </center>\n",
    "\n",
    "If $\\beta = 1$, we have the f1 score:\n",
    "### <center> $f_{1} = 2 \\frac{P R}{P + R}$ </center>\n",
    "\n",
    "If $\\beta < 1$, more weight to precision.\n",
    "\n",
    "If $\\beta > 1$, more weight to recall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The scores are a function of p_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 0 1 0 1]\n",
      "[0 1 1 0 0 1 0 0 0 1]\n",
      "accuracy 0.7\n",
      "recall 0.6\n",
      "precision 0.75\n",
      "f1 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "\n",
    "y_true = np.array([0,0,1,0,1,1,0,1,0,1]) # the true classification labels of the dataset\n",
    "y_pred_proba = np.array([0.3, 0.7,  0.55, 0.12, 0.45, 0.89, 0.41, 0.02, 0.29, 0.85])\n",
    "\n",
    "p_crit = 0.5\n",
    "\n",
    "y_pred = np.zeros(len(y_pred_proba),dtype=int)\n",
    "y_pred[y_pred_proba < p_crit] = 0\n",
    "y_pred[y_pred_proba >= p_crit] = 1\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred) # the predicted classification labels\n",
    "print('accuracy',accuracy_score(y_true,y_pred))\n",
    "print('recall',recall_score(y_true,y_pred))\n",
    "print('precision',precision_score(y_true,y_pred))\n",
    "print('f1',fbeta_score(y_true,y_pred,beta=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quiz 2\n",
    "Given the true and predicted labels, what are the accuracy, recall, precision, and f1 scores? \n",
    "\n",
    "Do not use sklearn to answer the question! First construct the confusion matrix and then calculate the scores by hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0,0,0,1,1,1,0,0]\n",
    "y_pred = [0,1,0,1,1,0,0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Evaluation metrics in supervised ML, part 1, classification</font>\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the terms in the confusion matrix</font>\n",
    "- <font color='LIGHTGRAY'>Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)</font>\n",
    "- **Choose a metric most appropriate for your problem**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How should you choose a metric?\n",
    "\n",
    "- What are the terms in the confusion matrix that you most (or least) care about?\n",
    "    - In an imbalanced dataset, TNs are large so you should use a metric that doesn't include TN\n",
    "    - no accuracy\n",
    "    - f score is usually preferred if your dataset is imbalanced\n",
    "- Will we act (intervene/apply treatment) on the model's prediction?\n",
    "    - Is it cheap to act? (e.g., mass email)\n",
    "       - we want to capture the largest fraction of the condition positive samples even if FPs will be large as a result\n",
    "       - recall or fbeta with beta > 1 (f1.5 or f2 are often used)\n",
    "    - Is it expensive to act? Do we have limited resources? Or treatment/action is costly?\n",
    "       - we want to make sure that the resources are allocated the best way possible\n",
    "       - want to make sure that a large fraction of the predicted positives are  true positives\n",
    "       - precision or fbeta with beta < 1 (f0.5 is often used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

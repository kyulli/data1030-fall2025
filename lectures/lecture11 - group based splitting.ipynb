{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca47521-f50a-446d-8e8f-033f49beedcc",
   "metadata": {},
   "source": [
    "# Mudcard\n",
    "- **what are other types of non iid data we will encounter?**\n",
    "    - group structure which we cover today\n",
    "- **What do you mean by lagged when looking at p?**\n",
    "    - Are you refering to AR(p)?\n",
    "    - p is the number of lagged features we use in the model\n",
    "    - when you have a time series observation, you need to bring it to a format which can be used by ML models\n",
    "    - you need a feature matrix and a target variable.\n",
    "    - the target variable is a recent observation\n",
    "    - the features are observations some dt in the past relative to the target variable\n",
    "    - this is autoregression, the second learning objective of the previous lecture\n",
    "- **are we going to cover all time series methods in our homework?**\n",
    "    - No, only AR and VAR\n",
    "    - Having said that, all of the time series methods we covered in class can come up in tech interviews\n",
    "    - In fact, I added all these models to the lecture because it was requested by DSI alumni\n",
    "- **I'm a bit confused about the matrix shown in this lecture of target variable and feature matrix, what are all the features? Are they not independent features in the non-time series dataset anymore?**\n",
    "    - No, they are lagged versions of the time series observation\n",
    "- **pretty clear - i hope i don't have to use time splitting - what to do with a mix of non/time-series features is a bit confusing but I think it's just complicated in general**\n",
    "    - Knowing who asked this question, I can tell you that you will use time series splitting and use a mix of regular and time series features. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf32c2",
   "metadata": {},
   "source": [
    "# <center> Lecture 11: Group-based and stratified splitting</center>\n",
    "\n",
    "By the end of this lecture, you will be able to\n",
    "- describe the motivation and importance of group-based splitting \n",
    "- apply various group-based splitting strategies\n",
    "- apply stratified splitting in a classification problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043a34a",
   "metadata": {},
   "source": [
    "# The supervised ML pipeline\n",
    "\n",
    "**0. Data collection/manipulation**: you might have multiple data sources and/or you might have more data than you need\n",
    "   - you need to be able to read in datasets from various sources (like csv, excel, SQL, parquet, etc)\n",
    "   - you need to be able to filter the columns/rows you need for your ML model\n",
    "   - you need to be able to combine the datasets into one dataframe \n",
    "\n",
    "**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "<span style=\"background-color: #FFFF00\">**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)</span>\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to be transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "**4. Choose an evaluation metric**: depends on the priorities of the stakeholders\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "**6. Tune the hyperparameters of your ML models (aka cross-validation or hyperparameter tuning)**\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "**7. Interpret your model**: black boxes are often not useful\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44303494",
   "metadata": {},
   "source": [
    "## Recall from Lecture 05\n",
    "\n",
    "- **the i.i.d. assumption**: the examples in the training set are independently and identically distributed according to $D$\n",
    "    - every $x_i$ is freshly sampled from $D$ and then labelled by $f$\n",
    "    - that is, $x_i$ and $y_i$ are picked independently of the other instances\n",
    "    - $S$ is a window through which the learner gets partial info about $D$ and the labeling function $f$\n",
    "    - the larger the sample gets, the more likely it is that $D$ and $f$ are accurately reflected\n",
    "- examples of not iid data:\n",
    "   - data generated by time-dependent processes\n",
    "   - data has group structure (samples collected from e.g., different subjects, experiments, measurement devices)\n",
    "- we will get back to this later in the term \n",
    "- if there is any sort of time or group structure in your data, it is likely non-iid\n",
    "    - **time series data**\n",
    "        - **values are not independent**\n",
    "        - stocks price\n",
    "        - covid19 cases\n",
    "        - weather data\n",
    "    - **group structure:**\n",
    "        - **samples are not identically distributed, $D$ might be different for each group**\n",
    "        - a person appears multiple times in the dataset (e.g., hospital/doctor visits)\n",
    "        - data is collected on multiple instruments (e.g., equipment failure prediction)\n",
    "        - geographical data (e.g., data collected about various cities, counties, states, countries)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6f944",
   "metadata": {},
   "source": [
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- **describe the motivation and importance of group-based splitting** \n",
    "- <font color='lightgray'>apply various group-based splitting strategies</font>\n",
    "- <font color='lightgray'>apply stratified splitting in a classification problem</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3124699-f9e4-4231-8b38-e47e0bc0c7b0",
   "metadata": {},
   "source": [
    "## Importance of group based splitting\n",
    "- iid is often assumed\n",
    "    - most auto-ML tools assume iid because it makes the problem easy to solve\n",
    "- one of the most common mistakes data science practitioners make is to assume iid when it is not correct\n",
    "- consequences:\n",
    "    - information leakage\n",
    "    - the model performs very well on the test set (low generalization error)\n",
    "    - when it is deployed, it performs poorly on new groups \n",
    "- datasets with group structure have some sort of group ID\n",
    "    - this can be customer ID, patient ID, instrument ID, sensor ID, etc.\n",
    "    - the group ID should NOT be used as a feature\n",
    "    - a unique identifier (often just a random sequence of characters) is not something an ML model can use\n",
    "    - it should be separated out and used as a group ID in group-based splitting methods (more on this later)\n",
    "- a categorical/ordinal feature is not usually a group ID! \n",
    "    - a group ID is usually a column that does not contain info the ML model can use\n",
    "    - the model can learn from categories \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67393755",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An example: seizure project\n",
    "- you can read the publication [here](https://ieeexplore.ieee.org/document/8857552)\n",
    "- classification problem:\n",
    "   - epileptic seizures vs. non-epileptic psychogenic seizures\n",
    "- data from empatica wrist sensor\n",
    "   - heart rate, skin temperature, EDA, blood volume pressure, acceleration\n",
    "- data collection:\n",
    "   - patients come to the hospital for a few days\n",
    "   - eeg and video recording to determine seizure type\n",
    "   - wrist sensor data is collected\n",
    "- question:\n",
    "   - Can we use the wrist sensor data to differentiate the two seizure types on new patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c394f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    patient ID            seizure_ID  ACC_mean  BVP_mean  EDA_mean    HR_mean  \\\n",
      "5           32  ID32__day3_arm_1_sz1  1.028539 -0.092102  0.112795  64.748167   \n",
      "6           32  ID32__day3_arm_1_sz1  1.027986  0.745437  0.130486  63.715667   \n",
      "7           32  ID32__day2_arm_1_sz0  1.002146  0.150810  0.189272  61.838500   \n",
      "8           32  ID32__day2_arm_1_sz0  1.005410  0.482859  1.226038  66.240833   \n",
      "9           32  ID32__day1_arm_1_sz0  0.997017 -0.925122  0.200990  56.103667   \n",
      "10          32  ID32__day1_arm_1_sz0  1.009207  1.618456  1.679754  64.668167   \n",
      "27          32  ID32__day1_arm_1_sz0  1.000290  0.046690  0.123165  54.289500   \n",
      "28          32  ID32__day1_arm_1_sz0  1.010351  0.125039  0.471180  65.060667   \n",
      "29          32  ID32__day2_arm_1_sz0  1.018163  0.254302  0.206010  61.875833   \n",
      "30          32  ID32__day2_arm_1_sz0  1.016785  1.242893  0.954649  66.216167   \n",
      "34          32  ID32__day3_arm_1_sz1  1.008867  0.070180  0.195966  65.995667   \n",
      "35          32  ID32__day3_arm_1_sz1  1.009554  0.222872  0.229909  63.871000   \n",
      "58          32  ID32__day3_arm_1_sz0  1.008873 -0.550857  0.177822  67.750833   \n",
      "79          32  ID32__day3_arm_1_sz0  1.026840  0.355953  0.205273  69.124667   \n",
      "\n",
      "    TEMP_mean  ACC_stdev   BVP_stdev  EDA_stdev  ...  BVP_50th  EDA_50th  \\\n",
      "5   36.944833   0.007469   36.486091   0.003905  ...     1.815  0.112710   \n",
      "6   36.676333   0.028190   84.964155   0.018598  ...     2.210  0.131921   \n",
      "7   38.600333   0.003747   64.194294   0.024278  ...     6.985  0.186026   \n",
      "8   39.296083   0.035257  165.665784   0.891139  ...     1.140  1.062333   \n",
      "9   34.656667   0.022648   77.013336   0.132008  ...     3.800  0.142159   \n",
      "10  34.678000   0.046047  146.515297   0.438236  ...     5.585  1.690537   \n",
      "27  38.467417   0.019826   51.176639   0.014530  ...     7.765  0.124259   \n",
      "28  38.448000   0.077142   61.205657   0.156170  ...     3.290  0.510114   \n",
      "29  37.681583   0.006805   40.982246   0.017099  ...     1.455  0.202632   \n",
      "30  37.979500   0.032493  219.277839   0.612229  ...    -5.785  1.028171   \n",
      "34  40.659458   0.021812   49.981175   0.013259  ...     3.480  0.198570   \n",
      "35  40.481333   0.048531   37.409681   0.031963  ...     0.695  0.228677   \n",
      "58  39.906667   0.021431   27.472002   0.003085  ...     1.955  0.178073   \n",
      "79  34.490167   0.008165   40.742936   0.003550  ...     3.090  0.206207   \n",
      "\n",
      "    HR_50th  TEMP_50th  ACC_75th  BVP_75th  EDA_75th  HR_75th  TEMP_75th  \\\n",
      "5    65.060      36.95  1.029947   16.3725  0.115591  65.8175     36.990   \n",
      "6    62.175      36.81  1.029947   21.1625  0.147611  66.2100     36.840   \n",
      "7    61.840      38.61  1.006085   43.8850  0.209086  61.9000     38.790   \n",
      "8    62.325      39.37  1.008872   49.4325  2.313129  71.0625     39.390   \n",
      "9    56.110      34.66  0.996821   35.2700  0.176739  56.6050     34.660   \n",
      "10   65.790      34.66  1.021497   70.4800  1.998868  67.7725     34.735   \n",
      "27   53.960      38.49  1.002073   39.8525  0.133226  54.7425     38.500   \n",
      "28   65.285      38.45  1.014302   25.4625  0.577047  69.4975     38.530   \n",
      "29   61.910      37.68  1.022811   29.2125  0.219282  61.9300     37.750   \n",
      "30   64.700      38.00  1.022811   65.5000  1.503002  69.5725     38.030   \n",
      "34   66.145      40.68  1.013700   13.1300  0.199852  67.0425     40.710   \n",
      "35   64.395      40.49  1.016106   12.9650  0.260383  65.9625     40.530   \n",
      "58   68.170      39.93  1.015264   17.8625  0.179354  68.5725     40.030   \n",
      "79   69.810      34.37  1.033260   13.4550  0.207488  70.0000     34.680   \n",
      "\n",
      "    label  \n",
      "5     0.0  \n",
      "6     0.0  \n",
      "7     0.0  \n",
      "8     0.0  \n",
      "9     0.0  \n",
      "10    0.0  \n",
      "27    0.0  \n",
      "28    0.0  \n",
      "29    0.0  \n",
      "30    0.0  \n",
      "34    0.0  \n",
      "35    0.0  \n",
      "58    0.0  \n",
      "79    0.0  \n",
      "\n",
      "[14 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/seizure_data.csv')\n",
    "print(df[df['patient ID'] == 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3466b68",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [ 86 190]\n",
      "balance: 0.6884057971014492\n"
     ]
    }
   ],
   "source": [
    "y = df['label']\n",
    "patient_ID = df['patient ID']\n",
    "seizure_ID = df['seizure_ID']\n",
    "X = df.drop(columns=['patient ID','seizure_ID','label'])\n",
    "classes, counts = np.unique(y,return_counts=True)\n",
    "print(classes, counts)\n",
    "print('balance:',np.max(counts/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9392b07",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(scaler,SVC())\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448c40e5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': np.float64(100.0), 'svc__gamma': np.float64(0.001)}\n",
      "best CV score: 0.9363636363636363\n",
      "test score: 0.8214285714285714\n",
      "{'svc__C': np.float64(10.0), 'svc__gamma': np.float64(0.01)}\n",
      "best CV score: 0.9136363636363635\n",
      "test score: 0.9285714285714286\n",
      "{'svc__C': np.float64(10.0), 'svc__gamma': np.float64(0.01)}\n",
      "best CV score: 0.9227272727272726\n",
      "test score: 0.9464285714285714\n",
      "{'svc__C': np.float64(10.0), 'svc__gamma': np.float64(0.01)}\n",
      "best CV score: 0.9318181818181819\n",
      "test score: 0.8928571428571429\n",
      "{'svc__C': np.float64(10.0), 'svc__gamma': np.float64(0.001)}\n",
      "best CV score: 0.9272727272727274\n",
      "test score: 0.875\n",
      "test accuracy: 0.89 +/- 0.04\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(5):\n",
    "    grid, test_score = ML_pipeline_kfold_GridSearchCV(X,y,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148a7df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This is wrong! A very bad case of data leakage!\n",
    "- the textbook case of data/information leakage!\n",
    "- if we just do KFold CV blindly, the points from the same patient end up in different sets\n",
    "   - when you deploy the model and apply it to data from new patients, that patient's data will be seen for the first time\n",
    "- the ML pipeline needs to mimic the intended use of the model!\n",
    "   - we want to split the points based on the patient ID!\n",
    "   - we want all points from the same patient to be in either train/CV/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4e97f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Group-based split: GroupKFold\n",
    "<center><img src=\"../figures/groupkfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8382fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "def ML_pipeline_groups_GridSearchCV(X,y,groups,random_state,n_folds):\n",
    "    # create a test set based on groups\n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    # check the split\n",
    "#     print(pd.unique(groups))\n",
    "#     print(pd.unique(groups_other))\n",
    "#     print(pd.unique(groups_test))\n",
    "    # splitter for _other\n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(scaler,SVC())\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other, groups=groups_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b547af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': np.float64(10.0), 'svc__gamma': np.float64(0.001)}\n",
      "best CV score: 0.7609139784946237\n",
      "test score: 0.6410256410256411\n",
      "{'svc__C': np.float64(0.1), 'svc__gamma': np.float64(0.01)}\n",
      "best CV score: 0.6522727272727272\n",
      "test score: 0.2711864406779661\n",
      "{'svc__C': np.float64(10.0), 'svc__gamma': np.float64(0.001)}\n",
      "best CV score: 0.5720073891625616\n",
      "test score: 0.9390243902439024\n",
      "{'svc__C': np.float64(10.0), 'svc__gamma': np.float64(0.001)}\n",
      "best CV score: 0.7061742424242425\n",
      "test score: 0.43243243243243246\n",
      "{'svc__C': np.float64(10000.0), 'svc__gamma': np.float64(0.001)}\n",
      "best CV score: 0.6082407407407406\n",
      "test score: 0.8901098901098901\n",
      "test accuracy: 0.63 +/- 0.26\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(5):\n",
    "    grid, test_score = ML_pipeline_groups_GridSearchCV(X,y,patient_ID,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d500fb2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The takeaway\n",
    "- an incorrect cross validation pipeline gives misleading results\n",
    "   - usually the model appears to be pretty accurate\n",
    "   - but the performance is poor when the model is deployed\n",
    "- this can be avoided by a careful cross validation pipeline\n",
    "   - think about how your model will be used\n",
    "   - mimic that future use in CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1168d-33fe-4231-8422-d4749583c0e3",
   "metadata": {},
   "source": [
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='lightgray'>describe the motivation and importance of group-based splitting</font>\n",
    "- **apply various group-based splitting strategies**\n",
    "- <font color='lightgray'>apply stratified splitting in a classification problem</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4186b3",
   "metadata": {},
   "source": [
    "# Let's take a look at group splitters using toy datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e8d42",
   "metadata": {},
   "source": [
    "## Group-based split: GroupKFold\n",
    "<center><img src=\"../figures/groupkfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6975330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.ones(shape=(8, 2))\n",
    "y = np.ones(shape=(8, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25193531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GroupKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class GroupKFold(GroupsConsumerMixin, _BaseKFold)\n",
      " |  GroupKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      " |\n",
      " |  K-fold iterator variant with non-overlapping groups.\n",
      " |\n",
      " |  Each group will appear exactly once in the test set across all folds (the\n",
      " |  number of distinct groups has to be at least equal to the number of folds).\n",
      " |\n",
      " |  The folds are approximately balanced in the sense that the number of\n",
      " |  samples is approximately the same in each test fold when `shuffle` is True.\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <group_k_fold>`.\n",
      " |\n",
      " |  For visualisation of cross-validation behaviour and\n",
      " |  comparison between common scikit-learn split methods\n",
      " |  refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |\n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |\n",
      " |  shuffle : bool, default=False\n",
      " |      Whether to shuffle the groups before splitting into batches.\n",
      " |      Note that the samples within each split will not be shuffled.\n",
      " |\n",
      " |      .. versionadded:: 1.6\n",
      " |\n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      " |      indices, which controls the randomness of each fold. Otherwise, this\n",
      " |      parameter has no effect.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |\n",
      " |      .. versionadded:: 1.6\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  Groups appear in an arbitrary order throughout the folds.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import GroupKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
      " |  >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
      " |  >>> groups = np.array([0, 0, 2, 2, 3, 3])\n",
      " |  >>> group_kfold = GroupKFold(n_splits=2)\n",
      " |  >>> group_kfold.get_n_splits(X, y, groups)\n",
      " |  2\n",
      " |  >>> print(group_kfold)\n",
      " |  GroupKFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):\n",
      " |  ...     print(f\"Fold {i}:\")\n",
      " |  ...     print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
      " |  ...     print(f\"  Test:  index={test_index}, group={groups[test_index]}\")\n",
      " |  Fold 0:\n",
      " |    Train: index=[2 3], group=[2 2]\n",
      " |    Test:  index=[0 1 4 5], group=[0 0 3 3]\n",
      " |  Fold 1:\n",
      " |    Train: index=[0 1 4 5], group=[0 0 3 3]\n",
      " |    Test:  index=[2 3], group=[2 2]\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  LeaveOneGroupOut : For splitting the data according to explicit\n",
      " |      domain-specific stratification of the dataset.\n",
      " |\n",
      " |  StratifiedKFold : Takes class information into account to avoid building\n",
      " |      folds with imbalanced class proportions (for binary or multiclass\n",
      " |      classification tasks).\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      GroupKFold\n",
      " |      GroupsConsumerMixin\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  set_split_request(self: sklearn.model_selection._split.GroupKFold, *, groups: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.model_selection._split.GroupKFold from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``split`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``split`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``split``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      groups : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``groups`` parameter in ``split``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  split(self, X, y=None, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |\n",
      " |      y : array-like of shape (n_samples,), default=None\n",
      " |          The target variable for supervised learning problems.\n",
      " |\n",
      " |      groups : array-like of shape (n_samples,)\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |\n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |\n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |\n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |\n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |\n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  __init_subclass__(**kwargs)\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |\n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |\n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GroupKFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8c4ae",
   "metadata": {},
   "source": [
    "## Group-based split: GroupShuffleSplit\n",
    "<center><img src=\"../figures/groupshufflesplit.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d4011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=10, train_size=.8, random_state=0)\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435e478",
   "metadata": {},
   "source": [
    "## Quiz 1\n",
    "Go back to the GroupKFold example above. What happens when you change n_splits to 4? Why?\n",
    "\n",
    "Why could we set the n_splits argument to 10 in GroupShuffleSplit? Check the manual of both methods to find the answer.\n",
    "\n",
    "Explain your answer in a couple of sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd050c-b1f7-46ec-8ff6-c38abb60b936",
   "metadata": {},
   "source": [
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='lightgray'>describe the motivation and importance of group-based splitting</font>\n",
    "- <font color='lightgray'>apply various group-based splitting strategies</font>\n",
    "- **apply stratified splitting in a classification problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5af1f-9626-4d05-8222-47ebe9f354f9",
   "metadata": {},
   "source": [
    "## Imbalanced data\n",
    "- imbalanced data: only a small fraction of the points are in one of the classes, usually ~5% or less but there is no hard limit here\n",
    "- examples:\n",
    "    - people visit a bank's website. do they sign up for a new credit card?\n",
    "        - most customers just browse and leave the page\n",
    "        - usually 1% or less of the customers get a credit card (class 1), the rest leaves the page without signing up (class 0).\n",
    "    - fraud detection\n",
    "        - only a tiny fraction of credit card payments are fraudulent\n",
    "    - rare disease diagnosis\n",
    "- the issue with imbalanced data:\n",
    "    - if you apply train_test_split or KFold, you might not have class 1 points in one of your sets by chance\n",
    "    - this is what we need to fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0fe5e-69c0-4195-9524-817fdb06f05c",
   "metadata": {},
   "source": [
    "## Solution: stratified splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50864b62-c8ed-4d8c-a2e7-27e6ed63306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "0    990\n",
      "1     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/imbalanced_data.csv')\n",
    "\n",
    "X = df[['feature1','feature2']]\n",
    "y = df['y']\n",
    "\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ad892f-5493-49c2-a89c-47537bf31295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**balance without stratification:**\n",
      "(array([0, 1]), array([591,   9]))\n",
      "(array([0]), array([200]))\n",
      "(array([0, 1]), array([199,   1]))\n",
      "**balance with stratification:**\n",
      "(array([0, 1]), array([594,   6]))\n",
      "(array([0, 1]), array([198,   2]))\n",
      "(array([0, 1]), array([198,   2]))\n"
     ]
    }
   ],
   "source": [
    "# 4 and 10\n",
    "\n",
    "random_state = 4\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,random_state=random_state)\n",
    "\n",
    "print('**balance without stratification:**')\n",
    "# a variation on the order of 1% which would be too much for imbalanced data!\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_val,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=y,random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=y_other,random_state=random_state)\n",
    "print('**balance with stratification:**')\n",
    "# very little variation (in the 4th decimal point only) which is important if the problem is imbalanced\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_val,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7344a-1ac3-41db-a27c-2538c27b070a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stratified folds\n",
    "<center><img src=\"../figures/stratified_kfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982af1e8-6d1a-4738-90b1-da3ca85ba068",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StratifiedKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class StratifiedKFold(_BaseKFold)\n",
      " |  StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      " |\n",
      " |  Stratified K-Fold cross-validator.\n",
      " |\n",
      " |  Provides train/test indices to split data in train/test sets.\n",
      " |\n",
      " |  This cross-validation object is a variation of KFold that returns\n",
      " |  stratified folds. The folds are made by preserving the percentage of\n",
      " |  samples for each class.\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <stratified_k_fold>`.\n",
      " |\n",
      " |  For visualisation of cross-validation behaviour and\n",
      " |  comparison between common scikit-learn split methods\n",
      " |  refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |\n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |\n",
      " |  shuffle : bool, default=False\n",
      " |      Whether to shuffle each class's samples before splitting into batches.\n",
      " |      Note that the samples within each split will not be shuffled.\n",
      " |\n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      " |      indices, which controls the randomness of each fold for each class.\n",
      " |      Otherwise, leave `random_state` as `None`.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import StratifiedKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([0, 0, 1, 1])\n",
      " |  >>> skf = StratifiedKFold(n_splits=2)\n",
      " |  >>> skf.get_n_splits(X, y)\n",
      " |  2\n",
      " |  >>> print(skf)\n",
      " |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
      " |  ...     print(f\"Fold {i}:\")\n",
      " |  ...     print(f\"  Train: index={train_index}\")\n",
      " |  ...     print(f\"  Test:  index={test_index}\")\n",
      " |  Fold 0:\n",
      " |    Train: index=[1 3]\n",
      " |    Test:  index=[0 2]\n",
      " |  Fold 1:\n",
      " |    Train: index=[0 2]\n",
      " |    Test:  index=[1 3]\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  The implementation is designed to:\n",
      " |\n",
      " |  * Generate test sets such that all contain the same distribution of\n",
      " |    classes, or as close as possible.\n",
      " |  * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
      " |    ``y = [1, 0]`` should not change the indices generated.\n",
      " |  * Preserve order dependencies in the dataset ordering, when\n",
      " |    ``shuffle=False``: all samples from class k in some test set were\n",
      " |    contiguous in y, or separated in y by samples from classes other than k.\n",
      " |  * Generate test sets where the smallest and largest differ by at most one\n",
      " |    sample.\n",
      " |\n",
      " |  .. versionchanged:: 0.22\n",
      " |      The previous implementation did not follow the last constraint.\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  RepeatedStratifiedKFold : Repeats Stratified K-Fold n times.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      StratifiedKFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  split(self, X, y, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |\n",
      " |          Note that providing ``y`` is sufficient to generate the splits and\n",
      " |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      " |          ``X`` instead of actual training data.\n",
      " |\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |          Stratification is done based on the y labels.\n",
      " |\n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |\n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |\n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting `random_state`\n",
      " |      to an integer.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |\n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |\n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |\n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  __init_subclass__(**kwargs)\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |\n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |\n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "help(StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a71edd-d6b2-4c4d-8f55-40fc310daf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test balance: (array([0, 1]), array([198,   2]))\n",
      "new fold\n",
      "(array([0, 1]), array([596,   4]))\n",
      "(array([0, 1]), array([196,   4]))\n",
      "new fold\n",
      "(array([0, 1]), array([593,   7]))\n",
      "(array([0, 1]), array([199,   1]))\n",
      "new fold\n",
      "(array([0, 1]), array([592,   8]))\n",
      "(array([0]), array([200]))\n",
      "new fold\n",
      "(array([0, 1]), array([595,   5]))\n",
      "(array([0, 1]), array([197,   3]))\n"
     ]
    }
   ],
   "source": [
    "# what we did before: variance in balance on the order of 1%\n",
    "random_state = 2\n",
    "\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=random_state)\n",
    "print('test balance:',np.unique(y_test,return_counts=True))\n",
    "\n",
    "# do KFold split on other\n",
    "kf = KFold(n_splits=4,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    print('new fold')\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print(np.unique(y_train,return_counts=True))\n",
    "    print(np.unique(y_val,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c18a82-5375-4fa4-98cd-98f47c9ae6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test balance: (array([0, 1]), array([198,   2]))\n",
      "new fold\n",
      "(array([0, 1]), array([594,   6]))\n",
      "(array([0, 1]), array([198,   2]))\n",
      "new fold\n",
      "(array([0, 1]), array([594,   6]))\n",
      "(array([0, 1]), array([198,   2]))\n",
      "new fold\n",
      "(array([0, 1]), array([594,   6]))\n",
      "(array([0, 1]), array([198,   2]))\n",
      "new fold\n",
      "(array([0, 1]), array([594,   6]))\n",
      "(array([0, 1]), array([198,   2]))\n"
     ]
    }
   ],
   "source": [
    "# stratified K Fold: variation in balance is very small (4th decimal point)\n",
    "random_state = 42\n",
    "\n",
    "# stratified train-test split\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,stratify=y,random_state=random_state)\n",
    "print('test balance:',np.unique(y_test,return_counts=True))\n",
    "\n",
    "# do StratifiedKFold split on other\n",
    "kf = StratifiedKFold(n_splits=4,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    print('new fold')\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print(np.unique(y_train,return_counts=True))\n",
    "    print(np.unique(y_val,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75803496-6c2d-4d40-b44d-b340dc689b84",
   "metadata": {},
   "source": [
    "## Mudcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0059aa8-b33c-45c1-a968-2c5c551a1600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

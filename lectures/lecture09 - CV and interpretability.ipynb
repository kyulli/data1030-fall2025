{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudcard\n",
    "- **Why do we need a validation set if we already have a test set?**\n",
    "    - the validation set is used for model selection\n",
    "    - the test set is used to estimate how well the model is expected to perform on previously unseen data points once it is deployed\n",
    "- **Is there a best practice for reading the Lasso and Ridge regressions directly from the graph?**\n",
    "    - I'm not sure what you are refering to.\n",
    "    - Please expand on it and submit your question on Ed\n",
    "- **Wondering why do we want coeffs to be exactly zero for feature selection?**\n",
    "    - If a coefficient is 0, the corresponding feature does not contribute to the prediction of the linear model\n",
    "    - y' = <w,X> = sum (w1 * X1 + w2 * X2 + w3 * X3 + ...)\n",
    "    - If w_i is 0, the corresponding feature X_i is not used in the prediction because w_i * X_i = 0 if w_i = 0\n",
    "- **How can we interpret the learned coefficients from LogisticRegression?**\n",
    "    - See PS5 problem 1 for the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Lecture 9: CV and Intro to Interpretability</center>\n",
    "\n",
    "By the end of this lecture, you will be able to\n",
    "- perform basic hyperparameter tuning \n",
    "- apply GridSearchCV\n",
    "- describe why interpretability is important\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The supervised ML pipeline\n",
    "\n",
    "**0. Data collection/manipulation**: you might have multiple data sources and/or you might have more data than you need\n",
    "   - you need to be able to read in datasets from various sources (like csv, excel, SQL, parquet, etc)\n",
    "   - you need to be able to filter the columns/rows you need for your ML model\n",
    "   - you need to be able to combine the datasets into one dataframe \n",
    "\n",
    "**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to be transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "**4. Choose an evaluation metric**: depends on the priorities of the stakeholders\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "<span style=\"background-color: #FFFF00\">**6. Tune the hyperparameters of your ML models (aka cross-validation or hyperparameter tuning)**</span>\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "<span style=\"background-color: #FFFF00\">**7. Interpret your model**: black boxes are often not useful</span>\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- **perform basic hyperparameter tuning**\n",
    "- <font color='LIGHTGRAY'>apply GridSearchCV</font>\n",
    "- <font color='LIGHTGRAY'>describe why interpretability is important</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's put everything together!\n",
    "\n",
    "\n",
    "import packages\n",
    "\n",
    "load your dataset\n",
    "\n",
    "create feature matrix and target variable\n",
    "\n",
    "for i in random_states:\n",
    "\n",
    "   - split the data\n",
    "   - preprocess it\n",
    "   - decide which hyperparameters you'll tune and what values you'll try\n",
    "   - for combo in hyperparameters:\n",
    "       - train your ML algo\n",
    "       - calculate training scores\n",
    "       - calculate validation scores\n",
    "   - select best model based on the mean and std validation scores\n",
    "   - predict the test set using the best model\n",
    "   - return your test score (generalization error)\n",
    "   - return the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The deliverables of an ML pipeline are:**\n",
    "- at the very least:\n",
    "    - the n number of best models you selected based on the vaidation scores\n",
    "        - yes, you need ALL of them\n",
    "    - the n number of test scores (or you can calculate mean and stdev test scores)\n",
    "- in some cases, you need your whole pipeline in a reproducable format like a container\n",
    "    - others might want to see how you preprocess and split your data\n",
    "    - what models you try\n",
    "    - your evaluation metric\n",
    "    - they might want to see your train and validation scores to verify the range of your hyperparameters\n",
    "    - etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/adult_data.csv')\n",
    "\n",
    "# let's separate the feature matrix X, and target variable y\n",
    "y = df['gross-income'] # remember, we want to predict who earns more than 50k or less than 50k\n",
    "X = df.loc[:, df.columns != 'gross-income'] # all other columns are features\n",
    "\n",
    "# collect which encoder to use on each feature\n",
    "# needs to be done manually\n",
    "ordinal_ftrs = ['education'] \n",
    "ordinal_cats = [[' Preschool',' 1st-4th',' 5th-6th',' 7th-8th',' 9th',' 10th',' 11th',' 12th',' HS-grad',\\\n",
    "                ' Some-college',' Assoc-voc',' Assoc-acdm',' Bachelors',' Masters',' Prof-school',' Doctorate']]\n",
    "onehot_ftrs = ['workclass','marital-status','occupation','relationship','race','sex','native-country']\n",
    "minmax_ftrs = ['age','hours-per-week']\n",
    "std_ftrs = ['capital-gain','capital-loss']\n",
    "\n",
    "# collect all the encoders into one preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "prep = Pipeline(steps=[('preprocessor', preprocessor)]) # for now we only preprocess, later we will add other steps here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "Let's recap preprocessing. Which of these statements are true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ParameterGrid in module sklearn.model_selection._search:\n",
      "\n",
      "class ParameterGrid(builtins.object)\n",
      " |  ParameterGrid(param_grid)\n",
      " |\n",
      " |  Grid of parameters with a discrete number of values for each.\n",
      " |\n",
      " |  Can be used to iterate over parameter value combinations with the\n",
      " |  Python built-in function iter.\n",
      " |  The order of the generated parameter combinations is deterministic.\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  param_grid : dict of str to sequence, or sequence of such\n",
      " |      The parameter grid to explore, as a dictionary mapping estimator\n",
      " |      parameters to sequences of allowed values.\n",
      " |\n",
      " |      An empty dict signifies default parameters.\n",
      " |\n",
      " |      A sequence of dicts signifies a sequence of grids to search, and is\n",
      " |      useful to avoid exploring parameter combinations that make no sense\n",
      " |      or have no effect. See the examples below.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.model_selection import ParameterGrid\n",
      " |  >>> param_grid = {'a': [1, 2], 'b': [True, False]}\n",
      " |  >>> list(ParameterGrid(param_grid)) == (\n",
      " |  ...    [{'a': 1, 'b': True}, {'a': 1, 'b': False},\n",
      " |  ...     {'a': 2, 'b': True}, {'a': 2, 'b': False}])\n",
      " |  True\n",
      " |\n",
      " |  >>> grid = [{'kernel': ['linear']}, {'kernel': ['rbf'], 'gamma': [1, 10]}]\n",
      " |  >>> list(ParameterGrid(grid)) == [{'kernel': 'linear'},\n",
      " |  ...                               {'kernel': 'rbf', 'gamma': 1},\n",
      " |  ...                               {'kernel': 'rbf', 'gamma': 10}]\n",
      " |  True\n",
      " |  >>> ParameterGrid(grid)[1] == {'kernel': 'rbf', 'gamma': 1}\n",
      " |  True\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  GridSearchCV : Uses :class:`ParameterGrid` to perform a full parallelized\n",
      " |      parameter search.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __getitem__(self, ind)\n",
      " |      Get the parameters that would be ``ind``th in iteration\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ind : int\n",
      " |          The iteration index\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict of str to any\n",
      " |          Equal to list(self)[ind]\n",
      " |\n",
      " |  __init__(self, param_grid)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __iter__(self)\n",
      " |      Iterate over the points in the grid.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : iterator over dict of str to any\n",
      " |          Yields dictionaries mapping each estimator parameter to one of its\n",
      " |          allowed values.\n",
      " |\n",
      " |  __len__(self)\n",
      " |      Number of points on the grid.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ParameterGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randoms state 1\n",
      "{'penalty': ['l1'], 'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'solver': ['saga'], 'max_iter': [10000]}\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.001)}\n",
      "    0.803030303030303 0.8015970515970516\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.01)}\n",
      "    0.8421375921375921 0.8444410319410319\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.1)}\n",
      "    0.8487919737919738 0.8539619164619164\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "    0.8510954135954136 0.8539619164619164\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(10.0)}\n",
      "    0.8511977886977887 0.8541154791154791\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(100.0)}\n",
      "    0.8509930384930385 0.8541154791154791\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1000.0)}\n",
      "    0.8509930384930385 0.8541154791154791\n",
      "best model parameters: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(10.0)}\n",
      "corresponding validation score: 0.8541154791154791\n",
      "test score: 0.8524489482573315\n",
      "randoms state 2\n",
      "{'penalty': ['l1'], 'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'solver': ['saga'], 'max_iter': [10000]}\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.001)}\n",
      "    0.80246723996724 0.8023648648648649\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.01)}\n",
      "    0.8422911547911548 0.8372235872235873\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.1)}\n",
      "    0.8510954135954136 0.8487407862407862\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "    0.8530405405405406 0.8513513513513513\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(10.0)}\n",
      "    0.8529381654381655 0.851044226044226\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(100.0)}\n",
      "    0.8530917280917281 0.8508906633906634\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1000.0)}\n",
      "    0.8530917280917281 0.8508906633906634\n",
      "best model parameters: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "corresponding validation score: 0.8513513513513513\n",
      "test score: 0.8541378780899739\n",
      "randoms state 3\n",
      "{'penalty': ['l1'], 'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'solver': ['saga'], 'max_iter': [10000]}\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.001)}\n",
      "    0.8028767403767404 0.7959152334152334\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.01)}\n",
      "    0.8447993447993448 0.8390663390663391\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.1)}\n",
      "    0.851044226044226 0.8481265356265356\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "    0.853552416052416 0.8493550368550369\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(10.0)}\n",
      "    0.8538083538083538 0.8488943488943489\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(100.0)}\n",
      "    0.854013104013104 0.8487407862407862\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1000.0)}\n",
      "    0.854013104013104 0.8487407862407862\n",
      "best model parameters: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "corresponding validation score: 0.8493550368550369\n",
      "test score: 0.8536772608628896\n",
      "randoms state 4\n",
      "{'penalty': ['l1'], 'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'solver': ['saga'], 'max_iter': [10000]}\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.001)}\n",
      "    0.8069717444717445 0.7976044226044227\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.01)}\n",
      "    0.8463349713349714 0.8389127764127764\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.1)}\n",
      "    0.854013104013104 0.8465909090909091\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "    0.8545761670761671 0.8481265356265356\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(10.0)}\n",
      "    0.8539619164619164 0.8468980343980343\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(100.0)}\n",
      "    0.854013104013104 0.8468980343980343\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1000.0)}\n",
      "    0.8539619164619164 0.8467444717444718\n",
      "best model parameters: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "corresponding validation score: 0.8481265356265356\n",
      "test score: 0.8473821587594043\n",
      "randoms state 5\n",
      "{'penalty': ['l1'], 'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'solver': ['saga'], 'max_iter': [10000]}\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.001)}\n",
      "    0.8003685503685504 0.8043611793611793\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.01)}\n",
      "    0.8435196560196561 0.8453624078624079\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.1)}\n",
      "    0.8495085995085995 0.856418918918919\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "    0.8517096642096642 0.8579545454545454\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(10.0)}\n",
      "    0.851965601965602 0.8574938574938575\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(100.0)}\n",
      "    0.8518632268632269 0.8570331695331695\n",
      "    {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1000.0)}\n",
      "    0.8518632268632269 0.8570331695331695\n",
      "best model parameters: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(1.0)}\n",
      "corresponding validation score: 0.8579545454545454\n",
      "test score: 0.8487640104406572\n"
     ]
    }
   ],
   "source": [
    "# let's train a logistic regression model\n",
    "\n",
    "# we will loop through nr_states random states so we will return nr_states test scores and nr_states trained models\n",
    "nr_states = 5\n",
    "test_scores = np.zeros(nr_states)\n",
    "final_models = []\n",
    "\n",
    "# loop through the different random states\n",
    "for i in range(nr_states):\n",
    "    print('randoms state '+str(i+1))\n",
    "\n",
    "    # first split to separate out the training set\n",
    "    X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,random_state=42*i)\n",
    "\n",
    "    # second split to separate out the validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,random_state=42*i)\n",
    "    \n",
    "    # preprocess the sets\n",
    "    X_train_prep = prep.fit_transform(X_train)\n",
    "    X_val_prep = prep.transform(X_val)\n",
    "    X_test_prep = prep.transform(X_test)\n",
    "\n",
    "    # decide which parameters to tune and what values to try\n",
    "    # the default value of any parameter not specified here will be used\n",
    "    param_grid = {\n",
    "                  'penalty': ['l1'], \n",
    "                  'C': np.logspace(-3,3,7), # only the inverse of the regularization strength is tuned\n",
    "                  'solver': ['saga'],\n",
    "                  'max_iter': [10000]\n",
    "                  } \n",
    "    print(param_grid)\n",
    "    \n",
    "    # we save the train and validation scores\n",
    "    # the validation scores are necessary to select the best model\n",
    "    # it's optional to save the train scores, it can be used to identify high bias and high variance models\n",
    "    train_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "    val_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "    models = []\n",
    "    \n",
    "    # loop through all combinations of hyperparameter combos\n",
    "    for p in range(len(ParameterGrid(param_grid))):\n",
    "        params = ParameterGrid(param_grid)[p]\n",
    "        print('   ',params) \n",
    "        clf = LogisticRegression(**params,random_state = 42*i) # initialize the classifier\n",
    "        clf.fit(X_train_prep,y_train) # fit the model\n",
    "        models.append(clf) # save it\n",
    "        # calculate train and validation accuracy scores\n",
    "        y_train_pred = clf.predict(X_train_prep)\n",
    "        train_score[p] = accuracy_score(y_train,y_train_pred)\n",
    "        y_val_pred = clf.predict(X_val_prep)\n",
    "        val_score[p] = accuracy_score(y_val,y_val_pred)\n",
    "        print('   ',train_score[p],val_score[p])\n",
    "    \n",
    "    # print out model parameters that maximize validation accuracy\n",
    "    print('best model parameters:',ParameterGrid(param_grid)[np.argmax(val_score)])\n",
    "    print('corresponding validation score:',np.max(val_score))\n",
    "    # collect and save the best model\n",
    "    final_models.append(models[np.argmax(val_score)])\n",
    "    # calculate and save the test score\n",
    "    y_test_pred = final_models[-1].predict(X_test_prep)\n",
    "    test_scores[i] = accuracy_score(y_test,y_test_pred)\n",
    "    print('test score:',test_scores[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to look out for\n",
    "- are the ranges of the hyperparameters wide enough?\n",
    "    - if you are unsure, save the training scores and plot the train and val scores!\n",
    "    - do you see underfitting? model performs poorly on both training and validation sets?\n",
    "    - do you see overfitting? model performs very good on training but worse on validation?\n",
    "    - if you don't see both, expand the range of the parameters and you'll likely find a better model\n",
    "    - read the manual and make sure you understand what the hyperparameter does in the model\n",
    "        - some parameters (like regularization parameters) should be evenly spaced in log because there is no upper bound\n",
    "        - some parameters (like l1_ratio for the elastic net) should be linearly spaced because they have clear lower and upper bounds\n",
    "    - **if the best hyperparameter is at the edge of your range, you definitely need to expand the range if you can**\n",
    "- not every hyperparameter is equally important\n",
    "    - some parameters have little to no impact on train and validation scores\n",
    "    - visualize the results if in doubt\n",
    "- is the best validation score similar to the test score?\n",
    "    - it's usual that the validation score is a bit better than the test score\n",
    "    - but if the difference between the two scores is significant over multiple random states, something could be off\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>perform basic hyperparameter tuning</font>\n",
    "- **apply GridSearchCV**\n",
    "- <font color='LIGHTGRAY'>describe why interpretability is important</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with folds\n",
    "- the steps are a bit different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "df = pd.read_csv('../data/adult_data.csv')\n",
    "\n",
    "# let's separate the feature matrix X, and target variable y\n",
    "y = df['gross-income'] # remember, we want to predict who earns more than 50k or less than 50k\n",
    "X = df.loc[:, df.columns != 'gross-income'] # all other columns are features\n",
    "\n",
    "ordinal_ftrs = ['education'] \n",
    "ordinal_cats = [[' Preschool',' 1st-4th',' 5th-6th',' 7th-8th',' 9th',' 10th',' 11th',' 12th',' HS-grad',\\\n",
    "                ' Some-college',' Assoc-voc',' Assoc-acdm',' Bachelors',' Masters',' Prof-school',' Doctorate']]\n",
    "onehot_ftrs = ['workclass','marital-status','occupation','relationship','race','sex','native-country']\n",
    "minmax_ftrs = ['age','hours-per-week']\n",
    "std_ftrs = ['capital-gain','capital-loss']\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "# all the same up to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "best model parameters: {'logisticregression__C': np.float64(100.0), 'logisticregression__max_iter': 10000, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n",
      "validation score: 0.8529253685503686\n",
      "test score: 0.8479963150621833\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "best model parameters: {'logisticregression__C': np.float64(1.0), 'logisticregression__max_iter': 10000, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n",
      "validation score: 0.8498925061425061\n",
      "test score: 0.8581298940580377\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "best model parameters: {'logisticregression__C': np.float64(1.0), 'logisticregression__max_iter': 10000, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n",
      "validation score: 0.852311117936118\n",
      "test score: 0.8506064793489944\n"
     ]
    }
   ],
   "source": [
    "# we will use GridSearchCV and the parameter names need to contain the ML algorithm you want to use\n",
    "# the parameters of some ML algorithms have the same name and this is how we avoid confusion\n",
    "\n",
    "param_grid = {\n",
    "            'logisticregression__penalty': ['l1'], \n",
    "            'logisticregression__solver': ['saga'],\n",
    "            'logisticregression__max_iter': [10000],\n",
    "            'logisticregression__C': np.logspace(-3,3,7) # only the inverse of the regularization strength is tuned\n",
    "                  } \n",
    "\n",
    "nr_states = 3\n",
    "test_scores = np.zeros(nr_states)\n",
    "final_models = []\n",
    "\n",
    "for i in range(nr_states):\n",
    "    # first split to separate out the test set\n",
    "    # we will use kfold on other\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=42*i)\n",
    "\n",
    "    # splitter for other\n",
    "    kf = KFold(n_splits=4,shuffle=True,random_state=42*i)\n",
    "\n",
    "    # the classifier\n",
    "    clf = LogisticRegression(**params,random_state = 42*i) # initialize the classifier\n",
    "\n",
    "    # let's put together a pipeline\n",
    "    # the pipeline will fit_transform the training set (3 folds), and transform the last fold used as validation\n",
    "    # then it will train the ML algorithm on the training set and evaluate it on the validation set\n",
    "    # it repeats this step automatically such that each fold will be an evaluation set once\n",
    "    pipe = make_pipeline(preprocessor,clf)\n",
    "\n",
    "    # use GridSearchCV\n",
    "    # GridSearchCV loops through all parameter combinations and collects the results \n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = 'accuracy',\n",
    "                        cv=kf, return_train_score = True, verbose=True)\n",
    "    \n",
    "    # this line fits the model on other and loops through the 4 different validation sets\n",
    "    grid.fit(X_other, y_other)\n",
    "    # save results into a data frame. feel free to print it and inspect it\n",
    "    results = pd.DataFrame(grid.cv_results_)\n",
    "    #print(results)\n",
    "\n",
    "    print('best model parameters:',grid.best_params_)\n",
    "    print('validation score:',grid.best_score_) # this is the mean validation score over all iterations\n",
    "    # save the model\n",
    "    final_models.append(grid)\n",
    "    # calculate and save the test score\n",
    "    y_test_pred = final_models[-1].predict(X_test)\n",
    "    test_scores[i] = accuracy_score(y_test,y_test_pred)\n",
    "    print('test score:',test_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__max_iter</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>param_logisticregression__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.141838</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'logisticregression__C': 0.001, 'logisticregr...</td>\n",
       "      <td>0.797758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813575</td>\n",
       "      <td>0.803209</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>7</td>\n",
       "      <td>0.804515</td>\n",
       "      <td>0.805078</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>0.799908</td>\n",
       "      <td>0.803056</td>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.296977</td>\n",
       "      <td>0.028689</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>0.835074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>0.843174</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>6</td>\n",
       "      <td>0.845055</td>\n",
       "      <td>0.843417</td>\n",
       "      <td>0.841779</td>\n",
       "      <td>0.842701</td>\n",
       "      <td>0.843238</td>\n",
       "      <td>0.001199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.522729</td>\n",
       "      <td>0.272064</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851812</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>5</td>\n",
       "      <td>0.853092</td>\n",
       "      <td>0.851556</td>\n",
       "      <td>0.850584</td>\n",
       "      <td>0.850788</td>\n",
       "      <td>0.851505</td>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.284712</td>\n",
       "      <td>0.586564</td>\n",
       "      <td>0.009746</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'logisticregression__C': 1.0, 'logisticregres...</td>\n",
       "      <td>0.850276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852733</td>\n",
       "      <td>0.852311</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854781</td>\n",
       "      <td>0.853552</td>\n",
       "      <td>0.853860</td>\n",
       "      <td>0.852836</td>\n",
       "      <td>0.853757</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.500764</td>\n",
       "      <td>1.776865</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'logisticregression__C': 10.0, 'logisticregre...</td>\n",
       "      <td>0.850584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852887</td>\n",
       "      <td>0.851812</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>4</td>\n",
       "      <td>0.854525</td>\n",
       "      <td>0.853296</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>0.852785</td>\n",
       "      <td>0.853629</td>\n",
       "      <td>0.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.036766</td>\n",
       "      <td>2.211653</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>100.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'logisticregression__C': 100.0, 'logisticregr...</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853348</td>\n",
       "      <td>0.852042</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>3</td>\n",
       "      <td>0.854576</td>\n",
       "      <td>0.853143</td>\n",
       "      <td>0.853860</td>\n",
       "      <td>0.852631</td>\n",
       "      <td>0.853552</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.543215</td>\n",
       "      <td>2.167504</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'logisticregression__C': 1000.0, 'logisticreg...</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853348</td>\n",
       "      <td>0.852081</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854576</td>\n",
       "      <td>0.853143</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>0.852682</td>\n",
       "      <td>0.853578</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.141838      0.011799         0.009326        0.000240   \n",
       "1       0.296977      0.028689         0.009311        0.000110   \n",
       "2       1.522729      0.272064         0.009537        0.000155   \n",
       "3       8.284712      0.586564         0.009746        0.000292   \n",
       "4      16.500764      1.776865         0.009721        0.000058   \n",
       "5      21.036766      2.211653         0.009714        0.000211   \n",
       "6      21.543215      2.167504         0.009744        0.000130   \n",
       "\n",
       "   param_logisticregression__C  param_logisticregression__max_iter  \\\n",
       "0                        0.001                               10000   \n",
       "1                        0.010                               10000   \n",
       "2                        0.100                               10000   \n",
       "3                        1.000                               10000   \n",
       "4                       10.000                               10000   \n",
       "5                      100.000                               10000   \n",
       "6                     1000.000                               10000   \n",
       "\n",
       "  param_logisticregression__penalty param_logisticregression__solver  \\\n",
       "0                                l1                             saga   \n",
       "1                                l1                             saga   \n",
       "2                                l1                             saga   \n",
       "3                                l1                             saga   \n",
       "4                                l1                             saga   \n",
       "5                                l1                             saga   \n",
       "6                                l1                             saga   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "0  {'logisticregression__C': 0.001, 'logisticregr...           0.797758  ...   \n",
       "1  {'logisticregression__C': 0.01, 'logisticregre...           0.835074  ...   \n",
       "2  {'logisticregression__C': 0.1, 'logisticregres...           0.846591  ...   \n",
       "3  {'logisticregression__C': 1.0, 'logisticregres...           0.850276  ...   \n",
       "4  {'logisticregression__C': 10.0, 'logisticregre...           0.850584  ...   \n",
       "5  {'logisticregression__C': 100.0, 'logisticregr...           0.850430  ...   \n",
       "6  {'logisticregression__C': 1000.0, 'logisticreg...           0.850430  ...   \n",
       "\n",
       "   split3_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.813575         0.803209        0.007001                7   \n",
       "1           0.850430         0.843174        0.005669                6   \n",
       "2           0.851812         0.850430        0.002260                5   \n",
       "3           0.852733         0.852311        0.001282                1   \n",
       "4           0.852887         0.851812        0.001080                4   \n",
       "5           0.853348         0.852042        0.001259                3   \n",
       "6           0.853348         0.852081        0.001296                2   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.804515            0.805078            0.802723   \n",
       "1            0.845055            0.843417            0.841779   \n",
       "2            0.853092            0.851556            0.850584   \n",
       "3            0.854781            0.853552            0.853860   \n",
       "4            0.854525            0.853296            0.853911   \n",
       "5            0.854576            0.853143            0.853860   \n",
       "6            0.854576            0.853143            0.853911   \n",
       "\n",
       "   split3_train_score  mean_train_score  std_train_score  \n",
       "0            0.799908          0.803056         0.002015  \n",
       "1            0.842701          0.843238         0.001199  \n",
       "2            0.850788          0.851505         0.000985  \n",
       "3            0.852836          0.853757         0.000698  \n",
       "4            0.852785          0.853629         0.000653  \n",
       "5            0.852631          0.853552         0.000735  \n",
       "6            0.852682          0.853578         0.000724  \n",
       "\n",
       "[7 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to look out for\n",
    "- less code but more stuff is going on in the background hidden from you\n",
    "    - looping over multiple folds\n",
    "    - .fit_transform and .transform is hidden from you\n",
    "- nevertheless, GridSearchCV and pipelines are pretty powerful\n",
    "- working with folds is a bit more robust because the best hyperparameter is selected based on the average score of multiple trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "Can we use GridSearchCV with sets prepared by train_test_split in advance? Use the sklearn manual or stackoverflow to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>perform basic hyperparameter tuning</font>\n",
    "- <font color='LIGHTGRAY'>apply GridSearchCV</font>\n",
    "- **describe why interpretability is important**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to interpretability\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "- A bank uses ML to review loans.\n",
    "\n",
    "|          | Requested | Received | Interest Rate |\n",
    "| -------- | :-: | :-: | :-: |\n",
    "| Person A | 10k       | 8k       | 4%            |\n",
    "| Person B | 10k       | 10k      | 5%            |\n",
    "| Person C | 10k       | 2k       | 5%            |\n",
    "\n",
    "- Which person received the worst outcome?\n",
    "- All three applicants have similar financial backgrounds\n",
    "- Person C is a member of the protected class but persons A and B are not\n",
    "- Person C sues the bank for discrimination\n",
    "- How can the bank check whether the algorithm does not discriminate against protected classes of people?\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "- An ML model predicts that a patient is at risk of heart disease\n",
    "- Doctors will ask why?\n",
    "- The 'why' is very important here\n",
    "- Should the prediction be trusted?\n",
    "    - If the model predicts heart disease because of the patient's zip code, the clinician will push back\n",
    "        - bias or some spurious correlation is suspected, model needs to be revised\n",
    "    - If model predict high cholesterol is the main reason, that aligns with medical knowledge \n",
    "- An interpretable outcome can inform next steps!\n",
    "    - If high cholesterol is the main reason for the predicted heart disease risk, diet, life style changes, and statin might be the solution\n",
    "    - If family history is the main driver of the prediction, earlier screenings might be the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretable or explainable ML (XML or XAI)\n",
    "\n",
    "There are two main types:\n",
    "\n",
    "- global explanations\n",
    "    - does the model make predictions based on reasonable features?\n",
    "    - one value per feature, it is a vector of shape $(n_{ftrs})$\n",
    "    - it describes how important each feature is generally\n",
    "    - good start but cannot be used to explain predictions of one datapoint!\n",
    "- local explanations\n",
    "    - can we trust the model's prediction for one specific data point?\n",
    "    - one value per feature and data point, it is a 2D array with a shape of $(n_{points},n_{ftrs})$ - the same shape as your feature matrix\n",
    "    - it describes how important each feature is for predicting one particular data point\n",
    "    - required when working with human data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mud card"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
